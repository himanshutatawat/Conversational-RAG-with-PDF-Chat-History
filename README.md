# Conversational-RAG-with-PDF-Chat-History
This project is a Conversational RAG (Retrieval-Augmented Generation) system that allows users to upload PDFs, chat with an AI assistant, and retrieve context-aware responses using Groq's LLM, FAISS, ChromaDB, and Hugging Face embeddings.
# ğŸ“– Conversational RAG with PDF & Chat History ğŸš€  

This project is a **Conversational RAG (Retrieval-Augmented Generation) system** that allows users to **upload PDFs, chat with an AI assistant**, and **retrieve context-aware responses** using **Groq's LLM, FAISS, ChromaDB, and Hugging Face embeddings**.  

---

## âœ¨ Features  
âœ… **Upload & Process PDFs** â€“ Extract text from PDFs and create embeddings.  
âœ… **Context-Aware Chat** â€“ Uses session-based memory for conversational understanding.  
âœ… **Groq API Integration** â€“ Generates responses using the **Gemma2-9b-It** model.  
âœ… **Vector Search with ChromaDB & FAISS** â€“ Retrieves relevant document chunks for better responses.  
âœ… **Session-Based Chat History** â€“ Maintains chat history across user queries.  
âœ… **Fast & Lightweight** â€“ Built with **Streamlit** for a simple UI.  

---

## ğŸ› ï¸ Installation & Setup  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/your-username/conversational-rag.git
cd conversational-rag
```
### 2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)
```bash

Edit
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```
### 3ï¸âƒ£ Install Dependencies
```bash

pip install -r requirements.txt
```
### 4ï¸âƒ£ Set Up Environment Variables
Create a .env file in the root directory and add the following:

```ini

HF_TOKEN="your-huggingface-token"
GROQ_API_KEY="your-groq-api-key"
```
Replace your-huggingface-token and your-groq-api-key with your actual API keys.

### 5ï¸âƒ£ Run the Application
```bash

streamlit run app.py
```
Then, open the Streamlit app in your browser to start chatting with your PDF-based AI assistant!

### ğŸ“ Project Structure
```bash

ğŸ“‚ conversational-rag
â”‚-- ğŸ“œ app.py                  # Main Streamlit application
â”‚-- ğŸ“œ requirements.txt        # Required dependencies
â”‚-- ğŸ“œ .env                    # Environment variables (ignored in .gitignore)
â”‚-- ğŸ“œ README.md               # Project documentation
â”‚-- ğŸ“‚ chroma_db               # Stores vector embeddings (created at runtime)
â”‚-- ğŸ“‚ temp.pdf                # Temporary storage for uploaded PDFs
```
### ğŸ¯ How to Use
1ï¸âƒ£ Upload a PDF using the UI.
2ï¸âƒ£ Enter your Groq API key to authenticate the model.
3ï¸âƒ£ Ask questions based on the documentâ€™s content.
4ï¸âƒ£ The AI retrieves relevant information and generates answers.
5ï¸âƒ£ Chat history is stored for a natural conversation flow.

### ğŸ“¦ Dependencies
This project requires the following Python packages:

streamlit
langchain
langchain_groq
langchain_openai
langchain_huggingface
langchain_chroma
langchain_community
chromadb
faiss-cpu
pypdf
python-dotenv
To install all dependencies, run:

```bash

pip install -r requirements.txt
```
